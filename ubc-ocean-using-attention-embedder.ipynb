{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n#         break\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-24T14:27:28.239348Z","iopub.execute_input":"2023-10-24T14:27:28.239672Z","iopub.status.idle":"2023-10-24T14:27:28.245254Z","shell.execute_reply.started":"2023-10-24T14:27:28.239645Z","shell.execute_reply":"2023-10-24T14:27:28.244411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import All Libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.metrics import classification_report , confusion_matrix , accuracy_score , auc\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\n#from google.colab.patches import cv2_imshow\nfrom PIL import Image \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Input, Dense,Conv2D , MaxPooling2D, Flatten,BatchNormalization,Dropout\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport tensorflow_hub as hub \n\nfrom keras.applications.vgg19 import VGG19","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:26.077917Z","iopub.execute_input":"2023-11-16T14:10:26.078270Z","iopub.status.idle":"2023-11-16T14:10:34.912878Z","shell.execute_reply.started":"2023-11-16T14:10:26.078239Z","shell.execute_reply":"2023-11-16T14:10:34.912048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_csv_path = \"/kaggle/input/UBC-OCEAN/train.csv\"\ntest_csv_path = \"/kaggle/input/UBC-OCEAN/test.csv\"\n\ntrain_df = pd.read_csv(train_csv_path)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:34.914487Z","iopub.execute_input":"2023-11-16T14:10:34.914997Z","iopub.status.idle":"2023-11-16T14:10:34.951343Z","shell.execute_reply.started":"2023-11-16T14:10:34.914969Z","shell.execute_reply":"2023-11-16T14:10:34.950480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=train_df['label'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:34.952433Z","iopub.execute_input":"2023-11-16T14:10:34.952695Z","iopub.status.idle":"2023-11-16T14:10:35.119209Z","shell.execute_reply.started":"2023-11-16T14:10:34.952671Z","shell.execute_reply":"2023-11-16T14:10:35.118222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.scatter(train_df['image_width'],train_df['image_height'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.121910Z","iopub.execute_input":"2023-11-16T14:10:35.122251Z","iopub.status.idle":"2023-11-16T14:10:35.295988Z","shell.execute_reply.started":"2023-11-16T14:10:35.122218Z","shell.execute_reply":"2023-11-16T14:10:35.295112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['is_tma'] = train_df['is_tma'].astype('int8')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.297709Z","iopub.execute_input":"2023-11-16T14:10:35.298413Z","iopub.status.idle":"2023-11-16T14:10:35.304041Z","shell.execute_reply.started":"2023-11-16T14:10:35.298377Z","shell.execute_reply":"2023-11-16T14:10:35.303345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['is_tma'].value_counts().plot(kind=\"pie\",autopct=\"%.1f%%\")\nplt.title(\"Image Distributions on Train Data\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.305202Z","iopub.execute_input":"2023-11-16T14:10:35.305559Z","iopub.status.idle":"2023-11-16T14:10:35.450854Z","shell.execute_reply.started":"2023-11-16T14:10:35.305527Z","shell.execute_reply":"2023-11-16T14:10:35.449724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_thumbnails = os.listdir(\"/kaggle/input/UBC-OCEAN/train_thumbnails\")\ntrain_images = os.listdir(\"/kaggle/input/UBC-OCEAN/train_images\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.452417Z","iopub.execute_input":"2023-11-16T14:10:35.453398Z","iopub.status.idle":"2023-11-16T14:10:35.745174Z","shell.execute_reply.started":"2023-11-16T14:10:35.453361Z","shell.execute_reply":"2023-11-16T14:10:35.744356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = ['CC', 'EC', 'HGSC', 'LGSC', 'MC']\ntrain_df['label'] = train_df['label'].replace({'CC':0, 'EC':1, 'HGSC':2, 'LGSC':3, 'MC':4})\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.746403Z","iopub.execute_input":"2023-11-16T14:10:35.746694Z","iopub.status.idle":"2023-11-16T14:10:35.759261Z","shell.execute_reply.started":"2023-11-16T14:10:35.746668Z","shell.execute_reply":"2023-11-16T14:10:35.758429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_id']=train_df['image_id'].astype(\"int32\")\ntrain_df['label']=train_df['label'].astype(\"int8\")\ntrain_df['image_width']=train_df['image_width'].astype(\"int32\")\ntrain_df['image_height']=train_df['image_height'].astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.760374Z","iopub.execute_input":"2023-11-16T14:10:35.760683Z","iopub.status.idle":"2023-11-16T14:10:35.770210Z","shell.execute_reply.started":"2023-11-16T14:10:35.760659Z","shell.execute_reply":"2023-11-16T14:10:35.769339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df['label'].value_counts()\ntrain_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.774220Z","iopub.execute_input":"2023-11-16T14:10:35.774875Z","iopub.status.idle":"2023-11-16T14:10:35.791739Z","shell.execute_reply.started":"2023-11-16T14:10:35.774849Z","shell.execute_reply":"2023-11-16T14:10:35.790805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.792796Z","iopub.execute_input":"2023-11-16T14:10:35.793064Z","iopub.status.idle":"2023-11-16T14:10:35.802980Z","shell.execute_reply.started":"2023-11-16T14:10:35.793040Z","shell.execute_reply":"2023-11-16T14:10:35.801994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Images Preprocessing","metadata":{}},{"cell_type":"code","source":"Image.MAX_IMAGE_PIXELS = 10000000000\n# Define patch size and overlap (if needed)\npatch_size = (128,128)  # Adjust this according to your requirements\noverlap = 10  # Adjust this if you want overlapping patches\n\nimage_data = []\nimage_label = []\nempty_img=0\nfor img_id, label , tma in zip(train_df['image_id'],train_df['label'], train_df['is_tma']):\n    #print(img_id, label,  tma)\n    if tma==0:\n        img_name = str(img_id)+\"_thumbnail.png\"\n        large_image = Image.open(\"/kaggle/input/UBC-OCEAN/train_thumbnails/\"+img_name)\n        for y in range(0, large_image.height, patch_size[0] - overlap): # (0,2523,192)\n            for x in range(0, large_image.width, patch_size[1] - overlap):  # (0,3000,192)  224-32=192\n                patch = large_image.crop((x, y, x+patch_size[1], y+patch_size[0]))\n                image = np.array(patch)\n                if np.sum(image)==0:\n                    empty_img+=1\n                elif (np.sum(image[0:,0:50])==0) or (np.sum(image[0:,50:])==0) or (np.sum(image[0:,100:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:50,0:])==0) or (np.sum(image[50:,0:])==0) or (np.sum(image[100:,0:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:50,0:50])==0) or (np.sum(image[0:50,50:])==0):\n                    empty_img+=1\n                elif (np.sum(image[50:100,0:50])==0) or (np.sum(image[50:100,50:])==0):\n                    empty_img+=1\n                elif (np.sum(image[50:,0:100])==0) or (np.sum(image[80:,80:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:50,75:])==0) or (np.sum(image[50:,75:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:40,80:])==0) or (np.sum(image[80:,80:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:35,0:])==0) or (np.sum(image[80:,0:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:25,0:50])==0) or (np.sum(image[0:25,100:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:20,0:25])==0) or (np.sum(image[0:20,25:50])==0) or (np.sum(image[0:20,50:80])==0) or (np.sum(image[0:20,90:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:25,0:25])==0) or (np.sum(image[0:25,100:])==0) or (np.sum(image[100:,0:25])==0) or (np.sum(image[100:,100:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:15,0:])==0) or (np.sum(image[115:,0:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:,0:15])==0) or (np.sum(image[0:,115:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:20,0:20])==0) or (np.sum(image[0:20,110:])==0) or (np.sum(image[110:,0:20])==0) or (np.sum(image[110:,110:])==0):\n                    empty_img+=1\n                elif (np.sum(image[0:10,0:10])==0) or (np.sum(image[0:10,115:])==0) or (np.sum(image[0:10,40:60])==0) or (np.sum(image[0:10,80:100])==0):\n                    empty_img+=1\n                elif (np.sum(image[40:50,0:10])==0) or (np.sum(image[110:,80:100])==0) or (np.sum(image[70:85,70:90])==0) or (np.sum(image[50:60,110:])==0):\n                    empty_img+=1\n\n                else:\n                    image_data.append(image)\n                    image_label.append(label)\n        \n#     if tma==1:\n#         img_name = str(img_id)+\".png\"\n#         large_image = Image.open(\"/kaggle/input/UBC-OCEAN/train_images/\"+img_name)\n#         for y in range(0, large_image.height, patch_size[0] - overlap): # (0,2523,192)\n#             for x in range(0, large_image.width, patch_size[1] - overlap):  # (0,3000,192)  224-32=192\n#                 patch = large_image.crop((x, y, x+patch_size[1], y+patch_size[0]))\n#                 image = np.array(patch)\n#                 if np.sum(image)==0:\n#                     empty_img+=1\n#                 elif (np.sum(image[0:,0:50])==0) or (np.sum(image[0:,50:])==0) or (np.sum(image[0:,100:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:50,0:])==0) or (np.sum(image[50:,0:])==0) or (np.sum(image[100:,0:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:50,0:50])==0) or (np.sum(image[0:50,50:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[50:100,0:50])==0) or (np.sum(image[50:100,50:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[50:,0:100])==0) or (np.sum(image[80:,80:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:50,75:])==0) or (np.sum(image[50:,75:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:40,80:])==0) or (np.sum(image[80:,80:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:35,0:])==0) or (np.sum(image[80:,0:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:25,0:50])==0) or (np.sum(image[0:25,100:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:20,0:25])==0) or (np.sum(image[0:20,25:50])==0) or (np.sum(image[0:20,50:80])==0) or (np.sum(image[0:20,90:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:25,0:25])==0) or (np.sum(image[0:25,100:])==0) or (np.sum(image[100:,0:25])==0) or (np.sum(image[100:,100:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:15,0:])==0) or (np.sum(image[115:,0:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:,0:15])==0) or (np.sum(image[0:,115:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:20,0:20])==0) or (np.sum(image[0:20,110:])==0) or (np.sum(image[110:,0:20])==0) or (np.sum(image[110:,110:])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[0:10,0:10])==0) or (np.sum(image[0:10,115:])==0) or (np.sum(image[0:10,40:60])==0) or (np.sum(image[0:10,80:100])==0):\n#                     empty_img+=1\n#                 elif (np.sum(image[40:50,0:10])==0) or (np.sum(image[110:,80:100])==0) or (np.sum(image[70:85,70:90])==0) or (np.sum(image[50:60,110:])==0):\n#                     empty_img+=1\n                \n                    \n#                 else:\n#                     image_data.append(image)\n#                     image_label.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.804259Z","iopub.execute_input":"2023-11-16T14:10:35.804570Z","iopub.status.idle":"2023-11-16T14:14:30.721602Z","shell.execute_reply.started":"2023-11-16T14:10:35.804546Z","shell.execute_reply":"2023-11-16T14:14:30.720071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(len(image_data))\nprint(len(image_label))\nprint(empty_img)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:30.722823Z","iopub.execute_input":"2023-11-16T14:14:30.723239Z","iopub.status.idle":"2023-11-16T14:14:30.729801Z","shell.execute_reply.started":"2023-11-16T14:14:30.723191Z","shell.execute_reply":"2023-11-16T14:14:30.728567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:30.731534Z","iopub.execute_input":"2023-11-16T14:14:30.731874Z","iopub.status.idle":"2023-11-16T14:14:30.745182Z","shell.execute_reply.started":"2023-11-16T14:14:30.731840Z","shell.execute_reply":"2023-11-16T14:14:30.743563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Images Visualization","metadata":{}},{"cell_type":"code","source":"set(image_label)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:30.746463Z","iopub.execute_input":"2023-11-16T14:14:30.746862Z","iopub.status.idle":"2023-11-16T14:14:30.759435Z","shell.execute_reply.started":"2023-11-16T14:14:30.746826Z","shell.execute_reply":"2023-11-16T14:14:30.758134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Covert image data into array for training","metadata":{}},{"cell_type":"code","source":"x = np.array(image_data) \ny = np.array(image_label)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:30.760872Z","iopub.execute_input":"2023-11-16T14:14:30.761189Z","iopub.status.idle":"2023-11-16T14:14:32.490863Z","shell.execute_reply.started":"2023-11-16T14:14:30.761163Z","shell.execute_reply":"2023-11-16T14:14:32.490026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:32.492120Z","iopub.execute_input":"2023-11-16T14:14:32.492603Z","iopub.status.idle":"2023-11-16T14:14:32.497825Z","shell.execute_reply.started":"2023-11-16T14:14:32.492567Z","shell.execute_reply":"2023-11-16T14:14:32.496919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:35:18.009157Z","iopub.execute_input":"2023-11-16T08:35:18.009883Z","iopub.status.idle":"2023-11-16T08:35:18.018043Z","shell.execute_reply.started":"2023-11-16T08:35:18.009836Z","shell.execute_reply":"2023-11-16T08:35:18.017303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x,y=shuffle(x,y,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:35:18.022140Z","iopub.execute_input":"2023-11-16T08:35:18.022421Z","iopub.status.idle":"2023-11-16T08:35:18.027518Z","shell.execute_reply.started":"2023-11-16T08:35:18.022389Z","shell.execute_reply":"2023-11-16T08:35:18.026725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split The Data","metadata":{}},{"cell_type":"code","source":"x = x[:5000]\ny = y[:5000]","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:32.500692Z","iopub.execute_input":"2023-11-16T14:14:32.501076Z","iopub.status.idle":"2023-11-16T14:14:32.507238Z","shell.execute_reply.started":"2023-11-16T14:14:32.501051Z","shell.execute_reply":"2023-11-16T14:14:32.506443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nX_train,y_train=shuffle(x,y, random_state=452)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:32.508204Z","iopub.execute_input":"2023-11-16T14:14:32.508486Z","iopub.status.idle":"2023-11-16T14:14:32.590243Z","shell.execute_reply.started":"2023-11-16T14:14:32.508461Z","shell.execute_reply":"2023-11-16T14:14:32.589434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test ,y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle=True)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:36:56.727865Z","iopub.execute_input":"2023-11-16T08:36:56.728566Z","iopub.status.idle":"2023-11-16T08:36:56.809052Z","shell.execute_reply.started":"2023-11-16T08:36:56.728534Z","shell.execute_reply":"2023-11-16T08:36:56.808035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yest=y_test\nyest.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:35:18.495469Z","iopub.status.idle":"2023-11-16T08:35:18.495878Z","shell.execute_reply.started":"2023-11-16T08:35:18.495681Z","shell.execute_reply":"2023-11-16T08:35:18.495697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Scale The Data for Train images","metadata":{}},{"cell_type":"code","source":"x_train_scaled = x_train/255\nx_test_scaled = x_test/255","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:35:18.497103Z","iopub.status.idle":"2023-11-16T08:35:18.497586Z","shell.execute_reply.started":"2023-11-16T08:35:18.497334Z","shell.execute_reply":"2023-11-16T08:35:18.497357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Image Visualization","metadata":{}},{"cell_type":"markdown","source":"## Test Image Visualization","metadata":{}},{"cell_type":"markdown","source":"## Model Building Using VGG16 Model","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.applications import VGG16\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Dense, Flatten\n# from tensorflow.keras.optimizers import Adam\n# import tensorflow as tf\n# num_classes = 5\n# # Load the VGG16 model with ImageNet weights and exclude the top classification layer\n# base_model =VGG16(weights='imagenet', include_top=False, input_shape=(128,128, 3))\n\n# # Customize the top classification layers\n# x = base_model.output\n# x = Flatten()(x)\n# x = Dense(4096, activation='relu')(x)\n# x = Dense(4096, activation='relu')(x)\n# predictions = Dense(num_classes, activation='softmax')(x)  # Replace num_classes with the number of classes in your dataset\n\n# # Create the VGG16 model with your custom top layer\n# model = Model(inputs=base_model.input, outputs=predictions)\n\n# # Freeze pre-trained layers (optional)\n# for layer in base_model.layers:\n#     layer.trainable = False\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:35:18.498842Z","iopub.status.idle":"2023-11-16T08:35:18.499305Z","shell.execute_reply.started":"2023-11-16T08:35:18.499068Z","shell.execute_reply":"2023-11-16T08:35:18.499091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Dropout, Dense, Multiply, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import ResNet50\n\n# Encoder block\ndef encoder_block(inputs, filters, kernel_size, activation='relu'):\n    x = SeparableConv2D(filters, kernel_size, padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(activation)(x)\n    x = SeparableConv2D(filters, kernel_size, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation(activation)(x)\n    return x\n\n# Decoder block with attention\ndef decoder_block(inputs, skip_features, filters, kernel_size, activation='relu'):\n    x = SeparableConv2D(filters, kernel_size, padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(activation)(x)\n    x = SeparableConv2D(filters, kernel_size, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation(activation)(x)\n    x = Add()([x, skip_features])\n    return x\n\n# Attention block\ndef attention_block(inputs, skip_features):\n    g = Conv2D(filters=skip_features.shape[-1], kernel_size=(1, 1), strides=(1, 1), padding='same')(inputs)\n    x = Conv2D(filters=skip_features.shape[-1], kernel_size=(1, 1), strides=(1, 1), padding='same')(skip_features)\n    attn = Multiply()([g, x])\n    \n    # Use a 1x1 convolution to match shapes if needed\n    attn = Conv2D(filters=inputs.shape[-1], kernel_size=(1, 1), strides=(1, 1), padding='same')(attn)\n    \n    x = Add()([inputs, attn])\n    return x\n\n# Input layer\ninput_layer = Input(shape=(128, 128, 3))\n\n# Encoder\nencoder1 = encoder_block(input_layer, 64, 3)\nencoder2 = encoder_block(encoder1, 128, 3)\nencoder3 = encoder_block(encoder2, 256, 3)\n\n# Attention\nattention = attention_block(encoder3, encoder2)\n\n# Decoder\ndecoder1 = decoder_block(attention, encoder2, 128, 3)\ndecoder2 = decoder_block(decoder1, encoder1, 64, 3)\n# Global Average Pooling\nx = GlobalAveragePooling2D()(decoder2)\n\n# Fully connected layers\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput_layer = Dense(5, activation='softmax')(x)\n\n# Create the model\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Display model summary\nmodel.summary()\nmodel.compile(optimizer=tf.keras.optimizers.Nadam(0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:32.591808Z","iopub.execute_input":"2023-11-16T14:14:32.592168Z","iopub.status.idle":"2023-11-16T14:14:35.897417Z","shell.execute_reply.started":"2023-11-16T14:14:32.592134Z","shell.execute_reply":"2023-11-16T14:14:35.896508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Nadam(0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model on your new dataset\nhistory = model.fit(x_train_scaled, y_train, epochs=20, batch_size=16,\n                   validation_data=(x_test_scaled,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:41:30.771489Z","iopub.execute_input":"2023-11-16T08:41:30.772015Z","iopub.status.idle":"2023-11-16T08:41:30.831315Z","shell.execute_reply.started":"2023-11-16T08:41:30.771969Z","shell.execute_reply":"2023-11-16T08:41:30.829906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = ['CC','EC', 'HGSC', 'LGSC','MC']\nplt.figure(figsize=(16,8))\nfor i in range(10):\n    plt.subplot(2,5,i+1)\n    plt.imshow(x_test[i])\n    plt.title(f\"Actual Label:{class_labels[y_test[i]]}\\nPredicted Label:{class_labels[y_pred_test[i]]}\")\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T14:51:33.608939Z","iopub.status.idle":"2023-10-24T14:51:33.609291Z","shell.execute_reply.started":"2023-10-24T14:51:33.609110Z","shell.execute_reply":"2023-10-24T14:51:33.609125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b',linestyle = 'dashdot', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', linestyle = 'dashdot',label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b',linestyle = 'dashdot' ,label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',linestyle = 'dashdot',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n# Turn off the grid\nax[0].grid(False)\nax[1].grid(False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T18:09:38.328736Z","iopub.execute_input":"2023-10-24T18:09:38.329130Z","iopub.status.idle":"2023-10-24T18:09:38.827602Z","shell.execute_reply.started":"2023-10-24T18:09:38.329099Z","shell.execute_reply":"2023-10-24T18:09:38.826654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\n\n# Assuming 'model' is your Keras functional model\nx_train_each_class = ['CC','EC', 'HGSC', 'LGSC','MC']\n\n# Convert multiclass labels to one-hot encoding\ny_test_bin = label_binarize(y_test, classes=np.arange(4))\n\n# Get predicted probabilities for each class\ny_pred_proba = model.predict(x_test_scaled)\n\n# Calculate ROC curve and AUC for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(4):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curves for each class\nplt.figure(figsize=(8, 6))\nfor i in range(4):\n    plt.plot(fpr[i], tpr[i], label=f'Class {x_train_each_class[i]} (AUC= {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curves')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T16:54:29.455513Z","iopub.execute_input":"2023-10-24T16:54:29.456386Z","iopub.status.idle":"2023-10-24T16:54:33.770565Z","shell.execute_reply.started":"2023-10-24T16:54:29.456350Z","shell.execute_reply":"2023-10-24T16:54:33.769639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation on Train & Test Data","metadata":{}},{"cell_type":"code","source":"loss ,acc = model.evaluate(x_train_scaled, y_train)\nprint(\"Accuracy on Train Data:\",acc)\nprint()\nloss ,acc = model.evaluate(x_test_scaled, y_test )\nprint(\"Accuracy on Test Data:\",acc)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T14:27:39.532213Z","iopub.status.idle":"2023-10-24T14:27:39.532530Z","shell.execute_reply.started":"2023-10-24T14:27:39.532373Z","shell.execute_reply":"2023-10-24T14:27:39.532389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred=x.predict(X_test)\nY_pred[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-24T14:27:39.533985Z","iopub.status.idle":"2023-10-24T14:27:39.534315Z","shell.execute_reply.started":"2023-10-24T14:27:39.534157Z","shell.execute_reply":"2023-10-24T14:27:39.534173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test_scaled)\ny_pred_test = [np.argmax(i) for i in y_pred]","metadata":{"execution":{"iopub.status.busy":"2023-10-24T18:09:54.930301Z","iopub.execute_input":"2023-10-24T18:09:54.930947Z","iopub.status.idle":"2023-10-24T18:10:00.133936Z","shell.execute_reply.started":"2023-10-24T18:09:54.930913Z","shell.execute_reply":"2023-10-24T18:10:00.133128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(y_pred_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T14:27:39.537207Z","iopub.status.idle":"2023-10-24T14:27:39.537558Z","shell.execute_reply.started":"2023-10-24T14:27:39.537376Z","shell.execute_reply":"2023-10-24T14:27:39.537392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model to a file\n# mobilenet_model.save(\"mobilenet_model_3.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T14:27:39.538620Z","iopub.status.idle":"2023-10-24T14:27:39.538916Z","shell.execute_reply.started":"2023-10-24T14:27:39.538767Z","shell.execute_reply":"2023-10-24T14:27:39.538781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics Evaluation on Test Data","metadata":{}},{"cell_type":"code","source":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred_test))\nprint()\n\n\nprint(\"Classification Report:\\n\",classification_report(y_test,y_pred_test))","metadata":{"execution":{"iopub.status.busy":"2023-10-24T18:10:06.289455Z","iopub.execute_input":"2023-10-24T18:10:06.289831Z","iopub.status.idle":"2023-10-24T18:10:06.307247Z","shell.execute_reply.started":"2023-10-24T18:10:06.289801Z","shell.execute_reply":"2023-10-24T18:10:06.306245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=['CC','EC', 'HGSC', 'LGSC','MC']","metadata":{"execution":{"iopub.status.busy":"2023-10-24T18:10:22.540987Z","iopub.execute_input":"2023-10-24T18:10:22.541741Z","iopub.status.idle":"2023-10-24T18:10:22.545957Z","shell.execute_reply.started":"2023-10-24T18:10:22.541706Z","shell.execute_reply":"2023-10-24T18:10:22.544975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_data=confusion_matrix(y_test,y_pred_test)\ncm = pd.DataFrame(cm_data, columns=labels, index =labels)\ncm.index.name = 'Actual'\ncm.columns.name = 'Predicted'\nplt.figure(figsize = (5,5))\nplt.title('Confusion Matrix', fontsize = 20)\nsns.set(font_scale=1.2)\nax = sns.heatmap(cm, cbar=False, cmap=\"crest\", annot=True, annot_kws={\"size\": 16}, fmt='g')","metadata":{"execution":{"iopub.status.busy":"2023-10-24T18:10:23.524664Z","iopub.execute_input":"2023-10-24T18:10:23.525415Z","iopub.status.idle":"2023-10-24T18:10:23.829641Z","shell.execute_reply.started":"2023-10-24T18:10:23.525385Z","shell.execute_reply":"2023-10-24T18:10:23.828701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare Actual & Predicted Labels","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(24,40))\nfor i in range(60):\n    plt.subplot(10,6,i+1)\n    plt.imshow(x_test[i])\n    plt.title(f\"Actual Label:{class_labels[y_test[i]]}\\nPredicted Label:{class_labels[y_pred_test[i]]}\")\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T14:27:39.543992Z","iopub.status.idle":"2023-10-24T14:27:39.544299Z","shell.execute_reply.started":"2023-10-24T14:27:39.544152Z","shell.execute_reply":"2023-10-24T14:27:39.544165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport numpy as np\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=10, shuffle=True)\n\n# Lists to store accuracy values for each fold\ntrain_accuracies = []\nval_accuracies = []\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, test in kfold.split(X_train, y_train):\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n    # Fit data to model\n    history = model.fit(X_train[train], y_train[train], validation_data=(X_train[test], y_train[test]),\n                        epochs=10, verbose=0, batch_size=8)\n\n    # Calculate and print the training accuracy\n    train_loss, train_accuracy = model.evaluate(X_train[train], y_train[train], verbose=0)\n    print(f'Fold {fold_no} Training Loss: {train_loss}')\n    print(f'Fold {fold_no} Training Accuracy: {train_accuracy}')\n    train_accuracies.append(train_accuracy)\n\n    # Calculate and print the validation accuracy\n    val_loss, val_accuracy =model.evaluate(X_train[test], y_train[test], verbose=0)\n    print(f'Fold {fold_no} Validation Loss: {val_loss}')\n    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy}')\n    val_accuracies.append(val_accuracy)\n\n    # Increase fold number\n    fold_no += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:14:35.898627Z","iopub.execute_input":"2023-11-16T14:14:35.898925Z","iopub.status.idle":"2023-11-16T16:16:04.760625Z","shell.execute_reply.started":"2023-11-16T14:14:35.898899Z","shell.execute_reply":"2023-11-16T16:16:04.759586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}